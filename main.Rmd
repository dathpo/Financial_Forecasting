---
title: "Financial Forecasting"
output:
  html_document
---
```{r}
library(neuralnet)
library(quantmod)
library(caret)
library(ggplot2)
library(scales)
library(MLmetrics)
library(dplyr)
library(ggseas)
library(forecast)
library(seasonal)
library(reshape2)
library(DMwR)

tickers <- c("BTC-USD")
tickers <- sort(tickers)
ticker.returns = lapply(tickers, function(sym) {
  dailyReturn(na.omit(getSymbols(sym,
                                   src="yahoo",
                                   from="2015-01-22",
                                   to="2019-01-22",
                                   auto.assign=FALSE)))
})

df <- as.data.frame(do.call(merge.xts, ticker.returns))
names(df) <- tickers

df$date <- as.Date(rownames(df))
date.range <- seq(min(df$date), max(df$date), by = 1) 
missing.dates.df <- data.frame(date.range[!date.range %in% df$date])
names(missing.dates.df) <- "date"
missing.dates.df$`BTC-USD` <- NA
df <- rbind(missing.dates.df, df)
df <- df[order(df$date),]
names(df)[2] <- "return"
df.mean <- mean(na.omit(df$return))
df[is.na(df$return),]$return <- df.mean
rownames(df) <- df$date
df <- subset(df, select = c("return"))

head(df)
tail(df)
```
```{r}
unscaled.ret <- df$return
scaled.ret <- scale(df$return)
df$return <- scaled.ret
unscale <- function(scaled.vector) {
  unscaled.vector <- scaled.vector * attr(scaled.ret, 'scaled:scale') + attr(scaled.ret, 'scaled:center')
  return(unscaled.vector)
}
df <- data.frame(df,
                 x1=Lag(df, 1),
                 x2=Lag(df, 2),
                 x3=Lag(df, 3),
                 x4=Lag(df, 4),
                 x5=Lag(df, 5),
                 x6=Lag(df, 6),
                 x7=Lag(df, 7),
                 x8=Lag(df, 8),
                 x9=Lag(df, 9),
                 x10=Lag(df, 10)
)
names(df) <- c('y', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
nrow(df)
df
```

```{r}
df <- na.omit(df)
nrow(df)
df <- df[, c(2:11, 1)]
head(df)
```
```{r}
train.index <- round(0.7555 * nrow(df))
train.df <- df[1:train.index,]
test.df <- df[-(1:train.index),]
nrow(train.df)
nrow(test.df)
tail(train.df)
head(test.df)
```
```{r, fig.width=11, fig.height=4}
plot.train.df <- cbind(date = as.Date(rownames(train.df)), train.df)
plot.test.df <- cbind(date = as.Date(rownames(test.df)), test.df)
ggplot() +
geom_line(data=plot.train.df, aes(x=plot.train.df$date, y=unscale(plot.train.df$y), colour="Training")) +
geom_line(data=plot.test.df, aes(x=plot.test.df$date, y=unscale(plot.test.df$y), colour="Test")) +
xlab("Time") + ylab("Return") + scale_y_continuous(labels=percent) +
  scale_colour_manual(name="Legend", values = c("#377EB8", "black")) +
ggtitle("BTC-USD Daily Returns Feb 2015 - Feb 2019")
ggsave("btcperf.pdf", width=8, height=4)
```
```{r, fig.width=11, fig.height=5}
ggtsdisplay(unscale(train.df$y), main="Autocorrelation and Partial Autocorrelation",
            points=F, xlab="Time", ylab="Return")
GG_save_pdf = function(list, filename) {
  pdf(filename, 8, 5)
  for (p in list) {}
  dev.off()
  invisible(NULL)
}
GG_save_pdf(ggtsdisplay(unscale(train.df$y), main="Autocorrelation and Partial Autocorrelation",
            points=F, xlab="Time", ylab="Return"), "acf_pacf.pdf")
```
```{r, fig.width=11, fig.height=5}
train.weekly.ts <- ts(unscale(train.df$y), frequency = 7)
train.yearly.ts <- ts(unscale(train.df$y), frequency = 365.25)
train.yearly.ts %>% decompose %>% autoplot
ggsave("train_decomp.pdf", width=8, height=5)
```
```{r, fig.width=11, fig.height=4}
y <- train.weekly.ts
z <- fourier(train.yearly.ts, K=5)
zf <- fourier(train.yearly.ts, K=5, h=355)
fit <- auto.arima(y, xreg=z, seasonal=F)
fc <- forecast(fit, xreg=zf, h=355)
autoplot(fc) + xlab("Time") + ylab("Return") +
scale_y_continuous(labels=percent)
ggsave("train_test_arima.pdf", width=8, height=4)
```
```{r, fig.width=11, fig.height=4}
# hw <- HoltWinters(train.weekly.ts)
# hw.pred <- predict(hw, n.ahead = 355, prediction.interval = T, level = 0.95)
# plot(hw, hw.pred)

gg.hw <- hw(train.weekly.ts, h=355)
autoplot(gg.hw) + xlab("Time") + ylab("Return") +
scale_y_continuous(labels=percent)
ggsave("train_test_hw.pdf", width=8, height=4)
```
```{r, fig.width=11, fig.height=4}
stl.pred <- forecast(train.yearly.ts, h=355)
autoplot(stl.pred) + xlab("Time") + ylab("Return") +
scale_y_continuous(labels=percent)
ggsave("train_test_stl.pdf", width=8, height=4)
```
```{r}
x.test <- test.df[, 1:(length(names(df))-1)]
y.test <- test.df[, length(names(df))]
y.train <- train.df[, length(names(df))]
set.seed(42)
softplus <- function(x) {log(1+exp(x))}
net <- neuralnet(y~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,
                 train.df,
                 hidden = c(90, 60, 30),
                 threshold = 0.01
                 # stepmax = 1e+9,
                 # rep = 5,
                 # algorithm = "backprop", "rprop+", "rprop-", "sag", "slr",
                 # err.fct = "sse", "ce",
                 # act.fct = softplus
                 # act.fct = "logistic", "tanh"
                 # linear.output = TRUE
)
y.train.pred <- as.data.frame(net$net.result)
colnames(y.train.pred) <- c("V1")
net$result.matrix[1:3,]
```
```{r}
train.df.lag.ma <- rowMeans(train.df[,1:10])
test.df.lag.ma <- rowMeans(test.df[,1:10])

naive.train <- train.df$x1
naive.test <- test.df$x1

y.train.comp.df <- cbind(y.train, y.train.pred, y.train.pred-y.train, train.df.lag.ma, naive.train, plot.train.df$date)
colnames(y.train.comp.df) <- c("y_train", "y_pred", "nn_residual", "ma", "naive", "date")

pred <- neuralnet::compute(net, x.test)
y.test.pred <- as.data.frame(pred$net.result)
y.test.comp.df <- cbind(y.test, y.test.pred, y.test.pred-y.test, test.df.lag.ma, naive.test, as.vector(stl.pred$mean), plot.test.df$date)
colnames(y.test.comp.df) <- c("y_test", "y_pred", "nn_residual", "ma", "naive", "stl", "date")

cat("Neural Network Accuracy - Training Set:")
cat("\nMAE:", MLmetrics::MAE(y.train.pred$V1, y.train))
cat("\nRMSE:", MLmetrics::RMSE(y.train.pred$V1, y.train))
cat("\nMAPE:", MLmetrics::MAPE(y.train.pred$V1, y.train))

cat("\n\nNeural Network Accuracy - Test Set:")
cat("\nMAE:", MLmetrics::MAE(y.test.pred$V1, y.test))
cat("\nRMSE:", MLmetrics::RMSE(y.test.pred$V1, y.test))
cat("\nMAPE:", MLmetrics::MAPE(y.test.pred$V1, y.test))

cat("\n\nNeural Network RMSE Difference (Test - Train):\n")
nn.rmse.diff <- MLmetrics::RMSE(y.test.pred$V1, y.test) - MLmetrics::RMSE(y.train.pred$V1, y.train)
if (nn.rmse.diff > 0) {
  cat(nn.rmse.diff, "(Overfitting)")
} else {
  cat(nn.rmse.diff, "(Underfitting)")
}

cat("\n\n\n10-Day Moving Average Accuracy - Training Set:")
cat("\nMAE:", MLmetrics::MAE(y.train.comp.df$ma, y.train))
cat("\nRMSE:", MLmetrics::RMSE(y.train.comp.df$ma, y.train))
cat("\nMAPE:", MLmetrics::MAPE(y.train.comp.df$ma, y.train))

cat("\n\n10-Day Moving Average Accuracy - Test Set:")
cat("\nMAE:", MLmetrics::MAE(y.test.comp.df$ma, y.test))
cat("\nRMSE:", MLmetrics::RMSE(y.test.comp.df$ma, y.test))
cat("\nMAPE:", MLmetrics::MAPE(y.test.comp.df$ma, y.test))

cat("\n\n10-Day Moving Average RMSE Difference (Test - Train):\n")
ma.rmse.diff <- MLmetrics::RMSE(y.test.comp.df$ma, y.test) - MLmetrics::RMSE(y.train.comp.df$ma, y.train)
if (ma.rmse.diff > 0) {
  cat(ma.rmse.diff, "(Overfitting)")
} else {
  cat(ma.rmse.diff, "(Underfitting)")
}

cat("\n\n\nNaive Approach Accuracy - Training Set:")
cat("\nMAE:", MLmetrics::MAE(y.train.comp.df$naive, y.train))
cat("\nRMSE:", MLmetrics::RMSE(y.train.comp.df$naive, y.train))
cat("\nMAPE:", MLmetrics::MAPE(y.train.comp.df$naive, y.train))

cat("\n\nNaive Approach Accuracy - Test Set:")
cat("\nMAE:", MLmetrics::MAE(y.test.comp.df$naive, y.test))
cat("\nRMSE:", MLmetrics::RMSE(y.test.comp.df$naive, y.test))
cat("\nMAPE:", MLmetrics::MAPE(y.test.comp.df$naive, y.test))

cat("\n\nNaive Approach RMSE Difference (Test - Train):\n")
naive.rmse.diff <- MLmetrics::RMSE(y.test.comp.df$naive, y.test) - MLmetrics::RMSE(y.train.comp.df$naive, y.train)
if (naive.rmse.diff > 0) {
  cat(naive.rmse.diff, "(Overfitting)")
} else {
  cat(naive.rmse.diff, "(Underfitting)")
}

cat("\n\n\nSTL Forecasting Accuracy - Test Set:")
cat("\nMAE:", MLmetrics::MAE(y.test.comp.df$stl, y.test))
cat("\nRMSE:", MLmetrics::RMSE(y.test.comp.df$stl, y.test))
cat("\nMAPE:", MLmetrics::MAPE(y.test.comp.df$stl, y.test))
```
```{r}
RColorBrewer::brewer.pal(9, "Set1")
default.colours <- c("#F8766D", "#B79F00", "#00BA38", "#00BFC4", "#619CFF", "#F564E3")
default.colours
```
```{r, fig.width=11, fig.height=4}
ggplot(data=y.train.comp.df, aes(x=y.train.comp.df$date)) +
geom_line(aes(y=unscale(y.train.comp.df$y_train), colour="Actual")) +
geom_line(aes(y=unscale(y.train.comp.df$ma), colour="10-Day Moving Average")) +
xlab("Time") + ylab("Return") + scale_y_continuous(labels=percent) + 
scale_colour_manual(name="Legend", values= c("#FF7F00", "black")) +
ggtitle("Training Set - 10-Day Moving Average")
ggsave("train_ma.pdf", width=8, height=4)
```
```{r, fig.width=11, fig.height=4}
ggplot(data=y.train.comp.df, aes(x=y.train.comp.df$date)) +
geom_line(aes(y=unscale(y.train.comp.df$y_train), colour="Actual")) +
geom_line(aes(y=unscale(y.train.comp.df$y_pred), colour="Predicted")) +
# geom_line(aes(y=y.train.comp.df$nn_residual, colour="Residual"), linetype = "dotted") +
# geom_area(aes(y=y.train.comp.df$nn_residual), fill="lightblue", linetype="dotted", alpha=0.4) +
xlab("Time") + ylab("Return") + scale_y_continuous(labels=percent) + 
scale_colour_manual(name="Legend", values = c("black", "#F8766D", "#E41A1C")) +
ggtitle("Training Set - Neural Network - Actual vs Predicted Values")
ggsave("train_nn.pdf", width=8, height=4)
```
```{r, fig.width=11, fig.height=4}
ggplot(data=y.test.comp.df, aes(x=y.test.comp.df$date)) +
geom_line(aes(y=unscale(y.test.comp.df$y_test), colour="Actual")) +
geom_line(aes(y=unscale(y.test.comp.df$ma), colour="10-Day Moving Average")) +
xlab("Time") + ylab("Return") + scale_y_continuous(labels=percent) + 
scale_color_manual("Legend", values = c("#FF7F00","#377EB8")) +
ggtitle("Test Set - 10-Day Moving Average")
ggsave("test_ma.pdf", width=8, height=4)
```
```{r, fig.width=11, fig.height=4}
ggplot(data=y.test.comp.df, aes(x=y.test.comp.df$date)) +
geom_line(aes(y=unscale(y.test.comp.df$y_test), colour="Actual")) +
geom_line(aes(y=unscale(y.test.comp.df$y_pred), colour="Predicted")) +
# geom_line(aes(y=y.test.comp.df$nn_residual, colour="Residual"), linetype = "dotted") +
# geom_area(aes(y=y.test.comp.df$nn_residual), fill="lightblue", linetype="dotted", alpha=0.4) +
xlab("Time") + ylab("Return") + scale_y_continuous(labels=percent) + 
scale_colour_manual(name="Legend", values = c("#377EB8", "#F8766D")) +
ggtitle("Test Set - Neural Network - Actual vs Predicted Values")
ggsave("test_nn.pdf", width=8, height=4)
```
```{r, fig.width=11, fig.height=4}
ggplot(data=y.test.comp.df, aes(x=y.test.comp.df$date)) +
geom_line(aes(y=unscale(y.test.comp.df$y_test), colour="Actual")) +
geom_line(aes(y=y.test.comp.df$stl, colour="Predicted")) +
xlab("Time") + ylab("Return") + scale_y_continuous(labels=percent) + 
scale_colour_manual(name="Legend", values = c("#377EB8", "#4DAF4A")) +
ggtitle("Test Set - STL + ETS(A,N,N) - Actual vs Predicted Values")
ggsave("test_stl.pdf", width=8, height=4)
```
```{r, fig.width=6, fig.height=4}
ggplot(data=y.test.comp.df, aes(y=unscale(y.test.comp.df$y_test))) +
geom_point(aes(x=unscale(y.test.comp.df$y_pred), colour="Neural Network"), size=0.8) +
geom_point(aes(x=y.test.comp.df$stl, colour="STL + ETS(A,N,N)"), size=0.8) +
  geom_abline(colour="#377EB8") +
xlab("Predicted Return") + ylab("Actual Return") + scale_y_continuous(labels=percent) + 
scale_x_continuous(labels=percent) + 
scale_colour_manual(name="Legend", values = c("#F8766D", "#4DAF4A")) +
ggtitle("Test Set - Neural Network vs STL + ETS(A,N,N)")
ggsave("test_nn_stl.pdf", width=6, height=4)
```
```{r}
y.train.comp.df
y.test.comp.df
```
```{r, fig.width=11, fig.height=5}
plot(net)
```